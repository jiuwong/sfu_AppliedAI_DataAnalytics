{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiuwong/sfu_AppliedAI_DataAnalytics/blob/main/3_1_data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "987a7db9",
      "metadata": {
        "id": "987a7db9"
      },
      "source": [
        "<img src=\"https://sfudial.ca/wp-content/uploads/SFU-DIAL-Logo.png\" width=40%>&nbsp;&nbsp;&nbsp;&nbsp;<img src=\"https://www.sfu.ca/content/dam/sfu/images/brand_extension/SFU-Big-Data_Logo.png\" width=40%>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c17a4e0d",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "c17a4e0d"
      },
      "source": [
        "# Lab 3.1: Preparing & Transforming Data with AI\n",
        "\n",
        "Master AI-enhanced data preparation techniques using real-world datasets from the City of Vancouver. Learn to clean, integrate, and transform data with AI support while developing critical thinking skills for data quality decisions.\n",
        "\n",
        "**Use the TODOs and prompt your AI like a teammate. Think critically, experiment often, and document your process.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cbf441",
      "metadata": {
        "id": "c7cbf441"
      },
      "source": [
        "## üìä Datasets Used in This Lab\n",
        "\n",
        "This lab uses real data from the City of Vancouver's Open Data Portal:\n",
        "\n",
        "1. **Business Licences Dataset**\n",
        "   - üîó [Download CSV](https://vancouver.opendatasoft.com/explore/dataset/business-licences/export/)\n",
        "   - üìñ [Explore Dataset](https://opendata.vancouver.ca/explore/dataset/business-licences/)\n",
        "   - Contains: Business license information for all businesses operating in Vancouver\n",
        "\n",
        "2. **Heritage Sites Dataset**\n",
        "   - üîó [Download CSV](https://opendata.vancouver.ca/explore/dataset/heritage-sites/export/)\n",
        "   - üìñ [Explore Dataset](https://opendata.vancouver.ca/explore/dataset/heritage-sites/)\n",
        "   - Contains: Information about heritage buildings and sites in Vancouver\n",
        "\n",
        "**Why these datasets?** They demonstrate real-world data preparation challenges:\n",
        "- Missing values and data quality issues\n",
        "- Different data types and formats\n",
        "- Data integration across multiple sources\n",
        "- Geographic and temporal data handling\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/git-steb/f3a6ae26b021d6cee5cfc7d6bcde70fc/3_1_Data_Prep.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8825f01",
      "metadata": {
        "id": "b8825f01"
      },
      "source": [
        "## Lab Outline\n",
        "\n",
        "- **Part 1:** Set up your environment and load real-world datasets\n",
        "- **Part 2:** Clean data with AI-powered tools\n",
        "- **Part 3:** Integrate and engineer features with AI\n",
        "- **Part 4:** Transform and encode data for modeling\n",
        "- **Deliverable:** Reflection on AI-assisted data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d899e9e",
      "metadata": {
        "id": "0d899e9e"
      },
      "source": [
        "## Getting Help from Your AI Assistant\n",
        "\n",
        "**Why AI assistance matters:** AI tools can help you understand data quality issues, suggest cleaning strategies, and automate repetitive tasks. They're particularly valuable for data preparation where pattern recognition and decision-making are key.\n",
        "\n",
        "**Specific AI Prompts for Data Preparation:**\n",
        "\n",
        "**Data Quality Assessment:**\n",
        "- \"Analyze this dataset for missing values, outliers, and inconsistencies. What patterns do you see?\"\n",
        "- \"What data quality issues could impact downstream analysis? Rank them by severity.\"\n",
        "- \"Help me create a data quality report with specific metrics and recommendations.\"\n",
        "\n",
        "**Data Cleaning Strategies:**\n",
        "- \"What cleaning strategies would work best for this type of data? Consider the business context.\"\n",
        "- \"How should I handle these missing values? Show me multiple approaches with trade-offs.\"\n",
        "- \"Help me identify and resolve data inconsistencies in this column.\"\n",
        "\n",
        "**Feature Engineering:**\n",
        "- \"What features should I engineer for this analysis? Consider domain knowledge and data types.\"\n",
        "- \"Help me create meaningful business features from these raw data columns.\"\n",
        "- \"What feature interactions might be important for this use case?\"\n",
        "\n",
        "**Data Integration:**\n",
        "- \"How can I integrate these datasets effectively? What are the key challenges?\"\n",
        "- \"Help me identify the best join strategy for these tables.\"\n",
        "- \"What data validation should I perform after merging these datasets?\"\n",
        "\n",
        "**Encoding and Transformation:**\n",
        "- \"What encoding approach would work best for this variable? Consider cardinality and model type.\"\n",
        "- \"Help me choose the right scaling method for these features.\"\n",
        "- \"What transformation would make this data more suitable for machine learning?\"\n",
        "\n",
        "**Validation and Quality Control:**\n",
        "- \"Help me validate the quality of my cleaned data with specific tests.\"\n",
        "- \"What metrics should I track to ensure data preparation success?\"\n",
        "- \"How can I automate quality checks for future data updates?\"\n",
        "\n",
        "**Avoid vague prompts like \"clean this data\" - be specific about what you need!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45b0b6d",
      "metadata": {
        "id": "d45b0b6d"
      },
      "source": [
        "## Learning Objectives\n",
        "- [ ] Objective 1: Set up AI-enhanced data preparation environment\n",
        "- [ ] Objective 2: Clean data with AI-powered tools\n",
        "- [ ] Objective 3: Integrate and engineer features with AI\n",
        "- [ ] Objective 4: Transform and encode data for modeling\n",
        "- [ ] Objective 5: Reflect on AI-assisted data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d67e5235",
      "metadata": {
        "id": "d67e5235"
      },
      "source": [
        "## Lab Structure\n",
        "  1. **Setup & Preparation** - Environment setup and data loading\n",
        "  2. **Data Cleaning** - AI-assisted cleaning and quality assessment\n",
        "  3. **Data Integration** - Combining datasets with AI support\n",
        "  4. **Feature Engineering** - Creating new features with AI assistance\n",
        "  5. **Data Transformation** - Encoding and scaling for modeling\n",
        "  6. **Reflection** - Comparing approaches and documenting insights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a773676",
      "metadata": {
        "id": "1a773676"
      },
      "source": [
        "## Part 1: Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272c753c",
      "metadata": {
        "id": "272c753c"
      },
      "source": [
        "### Step 1: Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873463f9",
      "metadata": {
        "id": "873463f9"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install --quiet pandas numpy scikit-learn matplotlib seaborn plotly  # Double-commented for safety. Remove both # to install."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe45ed20",
      "metadata": {
        "id": "fe45ed20"
      },
      "source": [
        "### Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dc611d",
      "metadata": {
        "id": "03dc611d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38dfa3e9",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "38dfa3e9"
      },
      "source": [
        "### Step 3: Load Your Datasets (Vancouver Open Data)\n",
        "\n",
        "We'll work with two datasets from the City of Vancouver:\n",
        "\n",
        "### üìã Business Licences\n",
        "- **Download**: https://vancouver.opendatasoft.com/explore/dataset/business-licences/export/\n",
        "- **API URL** (used below): https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/business-licences/exports/csv\n",
        "\n",
        "### üèõÔ∏è Heritage Sites\n",
        "- **Download**: https://opendata.vancouver.ca/explore/dataset/heritage-sites/export/\n",
        "- **API URL** (used below): https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/heritage-sites/exports/csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b9454b",
      "metadata": {
        "id": "f7b9454b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Business Licences\n",
        "business_url = \"https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/business-licences/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B\"\n",
        "business_df = pd.read_csv(business_url, delimiter=';')\n",
        "\n",
        "# Load Heritage Sites\n",
        "heritage_url = \"https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/heritage-sites/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B\"\n",
        "heritage_df = pd.read_csv(heritage_url, delimiter=';')\n",
        "\n",
        "print(\"Sample datasets created for demonstration\")\n",
        "print(f\"Business dataset shape: {business_df.shape}\")\n",
        "print(f\"Heritage dataset shape: {heritage_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcbbb562",
      "metadata": {
        "id": "fcbbb562"
      },
      "source": [
        "## Part 2: Data Cleaning with AI\n",
        "\n",
        "**Why data cleaning matters:** Real-world data is messy. Missing values, inconsistent formats, and outliers can lead to incorrect conclusions. AI tools can help identify these issues faster and suggest appropriate cleaning strategies, but human judgment is still essential for context-specific decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d2cb601",
      "metadata": {
        "id": "0d2cb601"
      },
      "source": [
        "### Step 1: Assess Data Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e696a3",
      "metadata": {
        "id": "21e696a3"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI tools to assess data quality\n",
        "print(\"Data Quality Assessment:\")\n",
        "print(\"\\nBusiness Dataset:\")\n",
        "print(f\"- Missing values: {business_df.isnull().sum().sum()}\")\n",
        "print(f\"- Duplicate rows: {business_df.duplicated().sum()}\")\n",
        "print(f\"- Data types: {business_df.dtypes.value_counts().to_dict()}\")\n",
        "\n",
        "print(\"\\nHeritage Dataset:\")\n",
        "print(f\"- Missing values: {heritage_df.isnull().sum().sum()}\")\n",
        "print(f\"- Duplicate rows: {heritage_df.duplicated().sum()}\")\n",
        "print(f\"- Data types: {heritage_df.dtypes.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f6cb8d9",
      "metadata": {
        "id": "3f6cb8d9"
      },
      "source": [
        "### Step 2: AI-Assisted Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0666f7f6",
      "metadata": {
        "id": "0666f7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "943cd568-1bf6-42d4-ae7d-8198d8d5f58c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI-Assisted Cleaning Strategies:\n",
            "1. Automated missing value detection and imputation\n",
            "2. Intelligent duplicate detection using similarity matching\n",
            "3. Pattern-based data validation\n",
            "4. Automated outlier detection and handling\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'business_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-835034826.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Example: Basic cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbusiness_df_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbusiness_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mheritage_df_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheritage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'business_df' is not defined"
          ]
        }
      ],
      "source": [
        "# TODO: Implement AI-assisted cleaning strategies\n",
        "print(\"AI-Assisted Cleaning Strategies:\")\n",
        "print(\"1. Automated missing value detection and imputation\")\n",
        "print(\"2. Intelligent duplicate detection using similarity matching\")\n",
        "print(\"3. Pattern-based data validation\")\n",
        "print(\"4. Automated outlier detection and handling\")\n",
        "\n",
        "# Example: Basic cleaning\n",
        "business_df_clean = business_df.copy()\n",
        "heritage_df_clean = heritage_df.copy()\n",
        "\n",
        "# Remove any potential duplicates\n",
        "business_df_clean = business_df_clean.drop_duplicates()\n",
        "heritage_df_clean = heritage_df_clean.drop_duplicates()\n",
        "\n",
        "print(f\"\\nCleaned datasets:\")\n",
        "print(f\"Business: {business_df_clean.shape}\")\n",
        "print(f\"Heritage: {heritage_df_clean.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51343a00",
      "metadata": {
        "id": "51343a00"
      },
      "source": [
        "## Part 3: Data Integration with AI\n",
        "\n",
        "**Why data integration matters:** Combining datasets from different sources can reveal insights that individual datasets cannot provide. However, integration challenges include handling different formats, resolving entity mismatches, and maintaining data quality. AI tools can help identify relationships and suggest integration strategies, but business logic is essential for correct merging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f630f4f",
      "metadata": {
        "id": "0f630f4f"
      },
      "source": [
        "### Step 1: Schema Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cad1ca3d",
      "metadata": {
        "id": "cad1ca3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "367c4df8-18cc-40a4-c12d-62d882bb645b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI-Powered Schema Matching:\n",
            "1. Automatic field mapping based on content similarity\n",
            "2. Intelligent data type inference\n",
            "3. Relationship detection between datasets\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'business_df_clean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3556200926.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Example: Basic integration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Find common addresses between business and heritage datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcommon_addresses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbusiness_df_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheritage_df_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'address'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nCommon addresses found: {len(common_addresses)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'business_df_clean' is not defined"
          ]
        }
      ],
      "source": [
        "# TODO: Use AI to match schemas between datasets\n",
        "print(\"AI-Powered Schema Matching:\")\n",
        "print(\"1. Automatic field mapping based on content similarity\")\n",
        "print(\"2. Intelligent data type inference\")\n",
        "print(\"3. Relationship detection between datasets\")\n",
        "\n",
        "# Example: Basic integration\n",
        "# Find common addresses between business and heritage datasets\n",
        "# First, ensure 'address' column exists or create it from existing address components if needed\n",
        "# For simplicity, let's use available address-like columns for this example\n",
        "\n",
        "# For business_df_clean, let's create a combined address string\n",
        "business_df_clean['full_address'] = business_df_clean['House'].astype(str) + ' ' + \\\n",
        "                                   business_df_clean['Street'].fillna('') + ', ' + \\\n",
        "                                   business_df_clean['City'].fillna('') + ', ' + \\\n",
        "                                   business_df_clean['Province'].fillna('') + ' ' + \\\n",
        "                                   business_df_clean['PostalCode'].fillna('')\n",
        "\n",
        "# For heritage_df_clean, let's create a combined address string\n",
        "heritage_df_clean['full_address'] = heritage_df_clean['StreetNumber'].astype(str) + ' ' + \\\n",
        "                                   heritage_df_clean['StreetName'].fillna('') + ', Vancouver, BC'\n",
        "\n",
        "# Convert to uppercase and strip whitespace for better matching\n",
        "business_df_clean['full_address'] = business_df_clean['full_address'].str.upper().str.strip()\n",
        "heritage_df_clean['full_address'] = heritage_df_clean['full_address'].str.upper().str.strip()\n",
        "\n",
        "common_addresses = set(business_df_clean['full_address'].dropna()) & set(heritage_df_clean['full_address'].dropna())\n",
        "print(f\"\\nCommon full addresses found: {len(common_addresses)}\")\n",
        "print(f\"A few examples of common addresses: {list(common_addresses)[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d53e2b5a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "d53e2b5a",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec95061",
        "outputId": "16742e6e-92c0-4c9e-8838-6e16d6553238"
      },
      "source": [
        "# Load Business Licences\n",
        "business_url = \"https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/business-licences/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B\"\n",
        "business_df = pd.read_csv(business_url, delimiter=';')\n",
        "\n",
        "# Load Heritage Sites\n",
        "heritage_url = \"https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/heritage-sites/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B\"\n",
        "heritage_df = pd.read_csv(heritage_url, delimiter=';')\n",
        "\n",
        "print(\"Sample datasets created for demonstration\")\n",
        "print(f\"Business dataset shape: {business_df.shape}\")\n",
        "print(f\"Heritage dataset shape: {heritage_df.shape}\")"
      ],
      "id": "7ec95061",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample datasets created for demonstration\n",
            "Business dataset shape: (197402, 25)\n",
            "Heritage dataset shape: (2495, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d123e36e",
        "outputId": "76249635-a86a-4587-97cf-95bd546376b9"
      },
      "source": [
        "# Example: Basic cleaning\n",
        "business_df_clean = business_df.copy()\n",
        "heritage_df_clean = heritage_df.copy()\n",
        "\n",
        "# Remove any potential duplicates\n",
        "business_df_clean = business_df_clean.drop_duplicates()\n",
        "heritage_df_clean = heritage_df_clean.drop_duplicates()\n",
        "\n",
        "print(f\"Cleaned datasets:\")\n",
        "print(f\"Business: {business_df_clean.shape}\")\n",
        "print(f\"Heritage: {heritage_df_clean.shape}\")"
      ],
      "id": "d123e36e",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned datasets:\n",
            "Business: (197402, 25)\n",
            "Heritage: (2495, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "467f5225"
      },
      "source": [
        "Now that the dataframes are loaded and cleaned, let's look at **Intelligent Data Type Inference**. Pandas can automatically infer data types, and the `infer_objects()` method can convert object columns to more specific types, which is useful for cleaning and memory optimization."
      ],
      "id": "467f5225"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ae0822",
        "outputId": "76afe492-653a-4cfa-fae6-0cbd65b0c899"
      },
      "source": [
        "print(\"Original Business Dataset Info:\")\n",
        "business_df_clean.info(verbose=True, show_counts=True)\n",
        "\n",
        "print(\"\\nInferring more precise dtypes for Business Dataset...\")\n",
        "business_df_inferred = business_df_clean.infer_objects()\n",
        "print(\"Inferred Business Dataset Info:\")\n",
        "business_df_inferred.info(verbose=True, show_counts=True)\n",
        "\n",
        "print(\"\\nOriginal Heritage Dataset Info:\")\n",
        "heritage_df_clean.info(verbose=True, show_counts=True)\n",
        "\n",
        "print(\"\\nInferring more precise dtypes for Heritage Dataset...\")\n",
        "heritage_df_inferred = heritage_df_clean.infer_objects()\n",
        "print(\"Inferred Heritage Dataset Info:\")\n",
        "heritage_df_inferred.info(verbose=True, show_counts=True)\n",
        "\n",
        "# You can compare the dtypes before and after infer_objects()\n",
        "# For example, to see if any 'object' columns were converted to 'int64', 'float64', or 'bool'."
      ],
      "id": "c3ae0822",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Business Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 197402 entries, 0 to 197401\n",
            "Data columns (total 25 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   FOLDERYEAR             197402 non-null  int64  \n",
            " 1   LicenceRSN             197402 non-null  int64  \n",
            " 2   LicenceNumber          197402 non-null  object \n",
            " 3   LicenceRevisionNumber  197402 non-null  int64  \n",
            " 4   BusinessName           185149 non-null  object \n",
            " 5   BusinessTradeName      74588 non-null   object \n",
            " 6   Status                 197402 non-null  object \n",
            " 7   IssuedDate             166488 non-null  object \n",
            " 8   ExpiredDate            166507 non-null  object \n",
            " 9   BusinessType           197402 non-null  object \n",
            " 10  BusinessSubType        20427 non-null   object \n",
            " 11  Unit                   47460 non-null   object \n",
            " 12  UnitType               47204 non-null   object \n",
            " 13  House                  106514 non-null  object \n",
            " 14  Street                 106531 non-null  object \n",
            " 15  City                   197364 non-null  object \n",
            " 16  Province               197342 non-null  object \n",
            " 17  Country                157173 non-null  object \n",
            " 18  PostalCode             105778 non-null  object \n",
            " 19  LocalArea              194683 non-null  object \n",
            " 20  NumberofEmployees      197402 non-null  float64\n",
            " 21  FeePaid                120246 non-null  float64\n",
            " 22  ExtractDate            197402 non-null  object \n",
            " 23  Geom                   99452 non-null   object \n",
            " 24  geo_point_2d           99452 non-null   object \n",
            "dtypes: float64(2), int64(3), object(20)\n",
            "memory usage: 37.7+ MB\n",
            "\n",
            "Inferring more precise dtypes for Business Dataset...\n",
            "Inferred Business Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 197402 entries, 0 to 197401\n",
            "Data columns (total 25 columns):\n",
            " #   Column                 Non-Null Count   Dtype  \n",
            "---  ------                 --------------   -----  \n",
            " 0   FOLDERYEAR             197402 non-null  int64  \n",
            " 1   LicenceRSN             197402 non-null  int64  \n",
            " 2   LicenceNumber          197402 non-null  object \n",
            " 3   LicenceRevisionNumber  197402 non-null  int64  \n",
            " 4   BusinessName           185149 non-null  object \n",
            " 5   BusinessTradeName      74588 non-null   object \n",
            " 6   Status                 197402 non-null  object \n",
            " 7   IssuedDate             166488 non-null  object \n",
            " 8   ExpiredDate            166507 non-null  object \n",
            " 9   BusinessType           197402 non-null  object \n",
            " 10  BusinessSubType        20427 non-null   object \n",
            " 11  Unit                   47460 non-null   object \n",
            " 12  UnitType               47204 non-null   object \n",
            " 13  House                  106514 non-null  object \n",
            " 14  Street                 106531 non-null  object \n",
            " 15  City                   197364 non-null  object \n",
            " 16  Province               197342 non-null  object \n",
            " 17  Country                157173 non-null  object \n",
            " 18  PostalCode             105778 non-null  object \n",
            " 19  LocalArea              194683 non-null  object \n",
            " 20  NumberofEmployees      197402 non-null  float64\n",
            " 21  FeePaid                120246 non-null  float64\n",
            " 22  ExtractDate            197402 non-null  object \n",
            " 23  Geom                   99452 non-null   object \n",
            " 24  geo_point_2d           99452 non-null   object \n",
            "dtypes: float64(2), int64(3), object(20)\n",
            "memory usage: 37.7+ MB\n",
            "\n",
            "Original Heritage Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2495 entries, 0 to 2494\n",
            "Data columns (total 20 columns):\n",
            " #   Column                            Non-Null Count  Dtype \n",
            "---  ------                            --------------  ----- \n",
            " 0   ID                                2495 non-null   int64 \n",
            " 1   StreetNumber                      2414 non-null   object\n",
            " 2   StreetName                        2414 non-null   object\n",
            " 3   AdditionalLocationInformation     86 non-null     object\n",
            " 4   Category                          2495 non-null   object\n",
            " 5   BuildingNameSpecifics             1064 non-null   object\n",
            " 6   EvaluationGroup                   2263 non-null   object\n",
            " 7   MunicipalDesignationM             2495 non-null   object\n",
            " 8   ProvincialDesignationP            2495 non-null   object\n",
            " 9   HeritageRevitalizationAgreementH  2495 non-null   object\n",
            " 10  InteriorDesignationI              2495 non-null   object\n",
            " 11  LandscapeDesignationL             2495 non-null   object\n",
            " 12  HeritageConservationAreaCA        2495 non-null   object\n",
            " 13  HeritageConservationCovenantHC    2495 non-null   object\n",
            " 14  FederalDesignationF               2495 non-null   object\n",
            " 15  Status                            2495 non-null   object\n",
            " 16  DateofLastUpdate                  2495 non-null   object\n",
            " 17  LocalArea                         2353 non-null   object\n",
            " 18  Geom                              2359 non-null   object\n",
            " 19  geo_point_2d                      2359 non-null   object\n",
            "dtypes: int64(1), object(19)\n",
            "memory usage: 390.0+ KB\n",
            "\n",
            "Inferring more precise dtypes for Heritage Dataset...\n",
            "Inferred Heritage Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2495 entries, 0 to 2494\n",
            "Data columns (total 20 columns):\n",
            " #   Column                            Non-Null Count  Dtype \n",
            "---  ------                            --------------  ----- \n",
            " 0   ID                                2495 non-null   int64 \n",
            " 1   StreetNumber                      2414 non-null   object\n",
            " 2   StreetName                        2414 non-null   object\n",
            " 3   AdditionalLocationInformation     86 non-null     object\n",
            " 4   Category                          2495 non-null   object\n",
            " 5   BuildingNameSpecifics             1064 non-null   object\n",
            " 6   EvaluationGroup                   2263 non-null   object\n",
            " 7   MunicipalDesignationM             2495 non-null   object\n",
            " 8   ProvincialDesignationP            2495 non-null   object\n",
            " 9   HeritageRevitalizationAgreementH  2495 non-null   object\n",
            " 10  InteriorDesignationI              2495 non-null   object\n",
            " 11  LandscapeDesignationL             2495 non-null   object\n",
            " 12  HeritageConservationAreaCA        2495 non-null   object\n",
            " 13  HeritageConservationCovenantHC    2495 non-null   object\n",
            " 14  FederalDesignationF               2495 non-null   object\n",
            " 15  Status                            2495 non-null   object\n",
            " 16  DateofLastUpdate                  2495 non-null   object\n",
            " 17  LocalArea                         2353 non-null   object\n",
            " 18  Geom                              2359 non-null   object\n",
            " 19  geo_point_2d                      2359 non-null   object\n",
            "dtypes: int64(1), object(19)\n",
            "memory usage: 390.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7deec96a",
      "metadata": {
        "id": "7deec96a"
      },
      "source": [
        "### Step 2: Record Linking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436b620a",
      "metadata": {
        "id": "436b620a"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement AI-assisted record linking\n",
        "print(\"AI-Assisted Record Linking:\")\n",
        "print(\"1. Fuzzy matching for similar records\")\n",
        "print(\"2. Machine learning-based similarity scoring\")\n",
        "print(\"3. Automated relationship detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "903c24f3",
      "metadata": {
        "id": "903c24f3"
      },
      "source": [
        "## Part 4: Feature Engineering with AI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdbeed13",
      "metadata": {
        "id": "fdbeed13"
      },
      "source": [
        "### Step 1: Automated Feature Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3827a0b1",
      "metadata": {
        "id": "3827a0b1"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI to generate new features\n",
        "print(\"AI-Powered Feature Engineering:\")\n",
        "print(\"1. Automated feature selection\")\n",
        "print(\"2. Intelligent feature combination\")\n",
        "print(\"3. Domain-specific feature generation\")\n",
        "\n",
        "# Example: Basic feature engineering\n",
        "business_df_clean['revenue_per_employee'] = business_df_clean['revenue'] / business_df_clean['employees']\n",
        "business_df_clean['business_size'] = pd.cut(business_df_clean['employees'],\n",
        "                                           bins=[0, 5, 20, 100, float('inf')],\n",
        "                                           labels=['Small', 'Medium', 'Large', 'Enterprise'])\n",
        "\n",
        "print(\"\\nNew features created:\")\n",
        "print(\"- revenue_per_employee: Revenue efficiency metric\")\n",
        "print(\"- business_size: Categorical business size classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04b4aa11",
      "metadata": {
        "id": "04b4aa11"
      },
      "source": [
        "### Step 2: Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7992b543",
      "metadata": {
        "id": "7992b543"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI to select the most relevant features\n",
        "print(\"AI-Assisted Feature Selection:\")\n",
        "print(\"1. Automated correlation analysis\")\n",
        "print(\"2. Machine learning-based importance ranking\")\n",
        "print(\"3. Automated feature interaction detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c788303",
      "metadata": {
        "id": "6c788303"
      },
      "source": [
        "## Part 5: Data Transformation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5996017",
      "metadata": {
        "id": "b5996017"
      },
      "source": [
        "### Step 1: Encoding Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcb68d9",
      "metadata": {
        "id": "2bcb68d9"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI to determine optimal encoding strategies\n",
        "print(\"AI-Powered Encoding Strategies:\")\n",
        "print(\"1. Intelligent encoding method selection\")\n",
        "print(\"2. Automated cardinality analysis\")\n",
        "print(\"3. Performance-based encoding optimization\")\n",
        "\n",
        "# Example: Basic encoding\n",
        "le = LabelEncoder()\n",
        "business_df_clean['license_type_encoded'] = le.fit_transform(business_df_clean['license_type'])\n",
        "\n",
        "print(\"\\nCategorical encoding applied:\")\n",
        "print(f\"License types: {business_df_clean['license_type'].unique()}\")\n",
        "print(f\"Encoded values: {business_df_clean['license_type_encoded'].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3789c13d",
      "metadata": {
        "id": "3789c13d"
      },
      "source": [
        "### Step 2: Scaling and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d8de7d",
      "metadata": {
        "id": "72d8de7d"
      },
      "outputs": [],
      "source": [
        "# TODO: Apply AI-assisted scaling and normalization\n",
        "print(\"AI-Assisted Scaling:\")\n",
        "print(\"1. Automated scaling method selection\")\n",
        "print(\"2. Intelligent outlier handling\")\n",
        "print(\"3. Performance-based scaling optimization\")\n",
        "\n",
        "# Example: Basic scaling\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = ['revenue', 'employees', 'revenue_per_employee']\n",
        "business_df_clean[numeric_cols] = scaler.fit_transform(business_df_clean[numeric_cols])\n",
        "\n",
        "print(\"\\nNumeric features scaled using StandardScaler\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29c24e2",
      "metadata": {
        "id": "f29c24e2"
      },
      "source": [
        "### Step 3: Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdc7b15b",
      "metadata": {
        "id": "bdc7b15b"
      },
      "outputs": [],
      "source": [
        "# TODO: Apply AI-assisted dimensionality reduction\n",
        "print(\"AI-Powered Dimensionality Reduction:\")\n",
        "print(\"1. Automated component selection\")\n",
        "print(\"2. Intelligent variance thresholding\")\n",
        "print(\"3. Performance-based reduction optimization\")\n",
        "\n",
        "# Example: Basic PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(business_df_clean[numeric_cols])\n",
        "\n",
        "print(f\"\\nPCA applied: {pca_features.shape}\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eaa05f3",
      "metadata": {
        "id": "5eaa05f3"
      },
      "source": [
        "## Part 6: Final Reflection and Learning Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ff4dc64",
      "metadata": {
        "id": "3ff4dc64"
      },
      "source": [
        "### Step 1: Compare Traditional vs AI-Assisted Approaches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a70d741b",
      "metadata": {
        "id": "a70d741b"
      },
      "outputs": [],
      "source": [
        "print(\"Traditional Data Preparation:\")\n",
        "print(\"- Manual code writing\")\n",
        "print(\"- Step-by-step analysis\")\n",
        "print(\"- Custom transformations\")\n",
        "print(\"- Full control over process\")\n",
        "\n",
        "print(\"\\nAI-Assisted Data Preparation:\")\n",
        "print(\"- Automated quality assessment\")\n",
        "print(\"- Intelligent cleaning suggestions\")\n",
        "print(\"- Smart feature engineering\")\n",
        "print(\"- Faster initial insights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "941799e2",
      "metadata": {
        "id": "941799e2"
      },
      "source": [
        "### Step 2: Critical Reflection on AI-Assisted Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebef0f77",
      "metadata": {
        "id": "ebef0f77"
      },
      "outputs": [],
      "source": [
        "print(\"=== REFLECTION QUESTIONS ===\")\n",
        "print()\n",
        "print(\"1. AI TOOL EFFECTIVENESS:\")\n",
        "print(\"   - What insights did AI tools reveal that you might have missed?\")\n",
        "print(\"   - Which AI suggestions were most valuable? Which were least helpful?\")\n",
        "print(\"   - How did AI change your approach to data preparation?\")\n",
        "print()\n",
        "print(\"2. PROCESS COMPARISON:\")\n",
        "print(\"   - How did the automated approach compare to manual data preparation?\")\n",
        "print(\"   - What are the trade-offs between control and automation?\")\n",
        "print(\"   - When would you choose each approach?\")\n",
        "print()\n",
        "print(\"3. LEARNING AND SKILL DEVELOPMENT:\")\n",
        "print(\"   - What new skills did you develop using AI tools?\")\n",
        "print(\"   - How did AI help you understand data quality issues?\")\n",
        "print(\"   - What would you do differently next time?\")\n",
        "print()\n",
        "print(\"4. PRACTICAL APPLICATION:\")\n",
        "print(\"   - How would you apply these techniques to a different dataset?\")\n",
        "print(\"   - What challenges might arise in a real business context?\")\n",
        "print(\"   - How would you explain AI-assisted data prep to a colleague?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a74c5a",
      "metadata": {
        "id": "52a74c5a"
      },
      "source": [
        "### Step 3: Document Your Learning Journey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32976889",
      "metadata": {
        "id": "32976889"
      },
      "outputs": [],
      "source": [
        "print(\"=== LEARNING DOCUMENTATION ===\")\n",
        "print()\n",
        "print(\"Key Insights Gained:\")\n",
        "print(\"- [ ] Understanding of AI tool capabilities and limitations\")\n",
        "print(\"- [ ] Experience with automated data quality assessment\")\n",
        "print(\"- [ ] Practice with AI-assisted feature engineering\")\n",
        "print(\"- [ ] Critical evaluation of AI suggestions\")\n",
        "print()\n",
        "print(\"Skills Developed:\")\n",
        "print(\"- [ ] Prompting AI tools effectively for data tasks\")\n",
        "print(\"- [ ] Evaluating AI-generated suggestions critically\")\n",
        "print(\"- [ ] Balancing automation with human oversight\")\n",
        "print(\"- [ ] Documenting data preparation decisions\")\n",
        "print()\n",
        "print(\"Next Steps:\")\n",
        "print(\"- [ ] Practice with different types of datasets\")\n",
        "print(\"- [ ] Experiment with more advanced AI tools\")\n",
        "print(\"- [ ] Develop your own data preparation workflows\")\n",
        "print(\"- [ ] Share insights with peers and colleagues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facdfda2",
      "metadata": {
        "id": "facdfda2"
      },
      "source": [
        "## Metacognitive Learning Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc53d11",
      "metadata": {
        "id": "5dc53d11"
      },
      "source": [
        "### Reflection Questions\n",
        "- **What did you learn about your own learning process?**\n",
        "- **How would you apply this to a different domain?**\n",
        "- **What connections do you see to other concepts?**\n",
        "- **What questions do you still have?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17984af4",
      "metadata": {
        "id": "17984af4"
      },
      "source": [
        "### Transfer Applications\n",
        "- **How would this work in healthcare?**\n",
        "- **What would change if you had 10 times more data?**\n",
        "- **How would you explain this to business executives?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72caabc7",
      "metadata": {
        "id": "72caabc7"
      },
      "source": [
        "### Expert Thinking\n",
        "- **What would an expert do differently?**\n",
        "- **What assumptions are you making?**\n",
        "- **How would you validate your approach?**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}