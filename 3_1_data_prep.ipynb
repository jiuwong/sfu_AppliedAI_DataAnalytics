{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiuwong/sfu_AppliedAI_DataAnalytics/blob/main/3_1_data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "987a7db9",
      "metadata": {
        "id": "987a7db9"
      },
      "source": [
        "<img src=\"https://sfudial.ca/wp-content/uploads/SFU-DIAL-Logo.png\" width=40%>&nbsp;&nbsp;&nbsp;&nbsp;<img src=\"https://www.sfu.ca/content/dam/sfu/images/brand_extension/SFU-Big-Data_Logo.png\" width=40%>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c17a4e0d",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "c17a4e0d"
      },
      "source": [
        "# Lab 3.1: Preparing & Transforming Data with AI\n",
        "\n",
        "Master AI-enhanced data preparation techniques using real-world datasets from the City of Vancouver. Learn to clean, integrate, and transform data with AI support while developing critical thinking skills for data quality decisions.\n",
        "\n",
        "**Use the TODOs and prompt your AI like a teammate. Think critically, experiment often, and document your process.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cbf441",
      "metadata": {
        "id": "c7cbf441"
      },
      "source": [
        "## üìä Datasets Used in This Lab\n",
        "\n",
        "This lab uses real data from the City of Vancouver's Open Data Portal:\n",
        "\n",
        "1. **Business Licences Dataset**\n",
        "   - üîó [Download CSV](https://vancouver.opendatasoft.com/explore/dataset/business-licences/export/)\n",
        "   - üìñ [Explore Dataset](https://opendata.vancouver.ca/explore/dataset/business-licences/)\n",
        "   - Contains: Business license information for all businesses operating in Vancouver\n",
        "\n",
        "2. **Heritage Sites Dataset**\n",
        "   - üîó [Download CSV](https://opendata.vancouver.ca/explore/dataset/heritage-sites/export/)\n",
        "   - üìñ [Explore Dataset](https://opendata.vancouver.ca/explore/dataset/heritage-sites/)\n",
        "   - Contains: Information about heritage buildings and sites in Vancouver\n",
        "\n",
        "**Why these datasets?** They demonstrate real-world data preparation challenges:\n",
        "- Missing values and data quality issues\n",
        "- Different data types and formats\n",
        "- Data integration across multiple sources\n",
        "- Geographic and temporal data handling\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/gist/git-steb/f3a6ae26b021d6cee5cfc7d6bcde70fc/3_1_Data_Prep.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8825f01",
      "metadata": {
        "id": "b8825f01"
      },
      "source": [
        "## Lab Outline\n",
        "\n",
        "- **Part 1:** Set up your environment and load real-world datasets\n",
        "- **Part 2:** Clean data with AI-powered tools\n",
        "- **Part 3:** Integrate and engineer features with AI\n",
        "- **Part 4:** Transform and encode data for modeling\n",
        "- **Deliverable:** Reflection on AI-assisted data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d899e9e",
      "metadata": {
        "id": "0d899e9e"
      },
      "source": [
        "## Getting Help from Your AI Assistant\n",
        "\n",
        "**Why AI assistance matters:** AI tools can help you understand data quality issues, suggest cleaning strategies, and automate repetitive tasks. They're particularly valuable for data preparation where pattern recognition and decision-making are key.\n",
        "\n",
        "**Specific AI Prompts for Data Preparation:**\n",
        "\n",
        "**Data Quality Assessment:**\n",
        "- \"Analyze this dataset for missing values, outliers, and inconsistencies. What patterns do you see?\"\n",
        "- \"What data quality issues could impact downstream analysis? Rank them by severity.\"\n",
        "- \"Help me create a data quality report with specific metrics and recommendations.\"\n",
        "\n",
        "**Data Cleaning Strategies:**\n",
        "- \"What cleaning strategies would work best for this type of data? Consider the business context.\"\n",
        "- \"How should I handle these missing values? Show me multiple approaches with trade-offs.\"\n",
        "- \"Help me identify and resolve data inconsistencies in this column.\"\n",
        "\n",
        "**Feature Engineering:**\n",
        "- \"What features should I engineer for this analysis? Consider domain knowledge and data types.\"\n",
        "- \"Help me create meaningful business features from these raw data columns.\"\n",
        "- \"What feature interactions might be important for this use case?\"\n",
        "\n",
        "**Data Integration:**\n",
        "- \"How can I integrate these datasets effectively? What are the key challenges?\"\n",
        "- \"Help me identify the best join strategy for these tables.\"\n",
        "- \"What data validation should I perform after merging these datasets?\"\n",
        "\n",
        "**Encoding and Transformation:**\n",
        "- \"What encoding approach would work best for this variable? Consider cardinality and model type.\"\n",
        "- \"Help me choose the right scaling method for these features.\"\n",
        "- \"What transformation would make this data more suitable for machine learning?\"\n",
        "\n",
        "**Validation and Quality Control:**\n",
        "- \"Help me validate the quality of my cleaned data with specific tests.\"\n",
        "- \"What metrics should I track to ensure data preparation success?\"\n",
        "- \"How can I automate quality checks for future data updates?\"\n",
        "\n",
        "**Avoid vague prompts like \"clean this data\" - be specific about what you need!**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45b0b6d",
      "metadata": {
        "id": "d45b0b6d"
      },
      "source": [
        "## Learning Objectives\n",
        "- [ ] Objective 1: Set up AI-enhanced data preparation environment\n",
        "- [ ] Objective 2: Clean data with AI-powered tools\n",
        "- [ ] Objective 3: Integrate and engineer features with AI\n",
        "- [ ] Objective 4: Transform and encode data for modeling\n",
        "- [ ] Objective 5: Reflect on AI-assisted data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d67e5235",
      "metadata": {
        "id": "d67e5235"
      },
      "source": [
        "## Lab Structure\n",
        "  1. **Setup & Preparation** - Environment setup and data loading\n",
        "  2. **Data Cleaning** - AI-assisted cleaning and quality assessment\n",
        "  3. **Data Integration** - Combining datasets with AI support\n",
        "  4. **Feature Engineering** - Creating new features with AI assistance\n",
        "  5. **Data Transformation** - Encoding and scaling for modeling\n",
        "  6. **Reflection** - Comparing approaches and documenting insights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a773676",
      "metadata": {
        "id": "1a773676"
      },
      "source": [
        "## Part 1: Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272c753c",
      "metadata": {
        "id": "272c753c"
      },
      "source": [
        "### Step 1: Install Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873463f9",
      "metadata": {
        "id": "873463f9"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install --quiet pandas numpy scikit-learn matplotlib seaborn plotly  # Double-commented for safety. Remove both # to install."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe45ed20",
      "metadata": {
        "id": "fe45ed20"
      },
      "source": [
        "### Step 2: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03dc611d",
      "metadata": {
        "id": "03dc611d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38dfa3e9",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "38dfa3e9"
      },
      "source": [
        "### Step 3: Load Your Datasets (Vancouver Open Data)\n",
        "\n",
        "We'll work with two datasets from the City of Vancouver:\n",
        "\n",
        "### üìã Business Licences\n",
        "- **Download**: https://vancouver.opendatasoft.com/explore/dataset/business-licences/export/\n",
        "- **API URL** (used below): https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/business-licences/exports/csv\n",
        "\n",
        "### üèõÔ∏è Heritage Sites\n",
        "- **Download**: https://opendata.vancouver.ca/explore/dataset/heritage-sites/export/\n",
        "- **API URL** (used below): https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/heritage-sites/exports/csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b9454b",
      "metadata": {
        "id": "f7b9454b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Business Licences\n",
        "business_url = \"https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/business-licences/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B\"\n",
        "business_df = pd.read_csv(business_url, delimiter=';')\n",
        "\n",
        "# Load Heritage Sites\n",
        "heritage_url = \"https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/heritage-sites/exports/csv?lang=en&timezone=America%2FLos_Angeles&use_labels=true&delimiter=%3B\"\n",
        "heritage_df = pd.read_csv(heritage_url, delimiter=';')\n",
        "\n",
        "print(\"Sample datasets created for demonstration\")\n",
        "print(f\"Business dataset shape: {business_df.shape}\")\n",
        "print(f\"Heritage dataset shape: {heritage_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcbbb562",
      "metadata": {
        "id": "fcbbb562"
      },
      "source": [
        "## Part 2: Data Cleaning with AI\n",
        "\n",
        "**Why data cleaning matters:** Real-world data is messy. Missing values, inconsistent formats, and outliers can lead to incorrect conclusions. AI tools can help identify these issues faster and suggest appropriate cleaning strategies, but human judgment is still essential for context-specific decisions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d2cb601",
      "metadata": {
        "id": "0d2cb601"
      },
      "source": [
        "### Step 1: Assess Data Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e696a3",
      "metadata": {
        "id": "21e696a3"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI tools to assess data quality\n",
        "print(\"Data Quality Assessment:\")\n",
        "print(\"\\nBusiness Dataset:\")\n",
        "print(f\"- Missing values: {business_df.isnull().sum().sum()}\")\n",
        "print(f\"- Duplicate rows: {business_df.duplicated().sum()}\")\n",
        "print(f\"- Data types: {business_df.dtypes.value_counts().to_dict()}\")\n",
        "\n",
        "print(\"\\nHeritage Dataset:\")\n",
        "print(f\"- Missing values: {heritage_df.isnull().sum().sum()}\")\n",
        "print(f\"- Duplicate rows: {heritage_df.duplicated().sum()}\")\n",
        "print(f\"- Data types: {heritage_df.dtypes.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f6cb8d9",
      "metadata": {
        "id": "3f6cb8d9"
      },
      "source": [
        "### Step 2: AI-Assisted Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0666f7f6",
      "metadata": {
        "id": "0666f7f6"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement AI-assisted cleaning strategies\n",
        "print(\"AI-Assisted Cleaning Strategies:\")\n",
        "print(\"1. Automated missing value detection and imputation\")\n",
        "print(\"2. Intelligent duplicate detection using similarity matching\")\n",
        "print(\"3. Pattern-based data validation\")\n",
        "print(\"4. Automated outlier detection and handling\")\n",
        "\n",
        "# Example: Basic cleaning\n",
        "business_df_clean = business_df.copy()\n",
        "heritage_df_clean = heritage_df.copy()\n",
        "\n",
        "# Remove any potential duplicates\n",
        "business_df_clean = business_df_clean.drop_duplicates()\n",
        "heritage_df_clean = heritage_df_clean.drop_duplicates()\n",
        "\n",
        "print(f\"\\nCleaned datasets:\")\n",
        "print(f\"Business: {business_df_clean.shape}\")\n",
        "print(f\"Heritage: {heritage_df_clean.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51343a00",
      "metadata": {
        "id": "51343a00"
      },
      "source": [
        "## Part 3: Data Integration with AI\n",
        "\n",
        "**Why data integration matters:** Combining datasets from different sources can reveal insights that individual datasets cannot provide. However, integration challenges include handling different formats, resolving entity mismatches, and maintaining data quality. AI tools can help identify relationships and suggest integration strategies, but business logic is essential for correct merging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f630f4f",
      "metadata": {
        "id": "0f630f4f"
      },
      "source": [
        "### Step 1: Schema Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad1ca3d",
      "metadata": {
        "id": "cad1ca3d"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI to match schemas between datasets\n",
        "print(\"AI-Powered Schema Matching:\")\n",
        "print(\"1. Automatic field mapping based on content similarity\")\n",
        "print(\"2. Intelligent data type inference\")\n",
        "print(\"3. Relationship detection between datasets\")\n",
        "\n",
        "# Example: Basic integration\n",
        "# Find common addresses between business and heritage datasets\n",
        "common_addresses = set(business_df_clean['address']) & set(heritage_df_clean['address'])\n",
        "print(f\"\\nCommon addresses found: {len(common_addresses)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7deec96a",
      "metadata": {
        "id": "7deec96a"
      },
      "source": [
        "### Step 2: Record Linking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436b620a",
      "metadata": {
        "id": "436b620a"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement AI-assisted record linking\n",
        "print(\"AI-Assisted Record Linking:\")\n",
        "print(\"1. Fuzzy matching for similar records\")\n",
        "print(\"2. Machine learning-based similarity scoring\")\n",
        "print(\"3. Automated relationship detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "903c24f3",
      "metadata": {
        "id": "903c24f3"
      },
      "source": [
        "## Part 4: Feature Engineering with AI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdbeed13",
      "metadata": {
        "id": "fdbeed13"
      },
      "source": [
        "### Step 1: Automated Feature Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3827a0b1",
      "metadata": {
        "id": "3827a0b1"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI to generate new features\n",
        "print(\"AI-Powered Feature Engineering:\")\n",
        "print(\"1. Automated feature selection\")\n",
        "print(\"2. Intelligent feature combination\")\n",
        "print(\"3. Domain-specific feature generation\")\n",
        "\n",
        "# Example: Basic feature engineering\n",
        "business_df_clean['revenue_per_employee'] = business_df_clean['revenue'] / business_df_clean['employees']\n",
        "business_df_clean['business_size'] = pd.cut(business_df_clean['employees'],\n",
        "                                           bins=[0, 5, 20, 100, float('inf')],\n",
        "                                           labels=['Small', 'Medium', 'Large', 'Enterprise'])\n",
        "\n",
        "print(\"\\nNew features created:\")\n",
        "print(\"- revenue_per_employee: Revenue efficiency metric\")\n",
        "print(\"- business_size: Categorical business size classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04b4aa11",
      "metadata": {
        "id": "04b4aa11"
      },
      "source": [
        "### Step 2: Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7992b543",
      "metadata": {
        "id": "7992b543"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI to select the most relevant features\n",
        "print(\"AI-Assisted Feature Selection:\")\n",
        "print(\"1. Automated correlation analysis\")\n",
        "print(\"2. Machine learning-based importance ranking\")\n",
        "print(\"3. Automated feature interaction detection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c788303",
      "metadata": {
        "id": "6c788303"
      },
      "source": [
        "## Part 5: Data Transformation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5996017",
      "metadata": {
        "id": "b5996017"
      },
      "source": [
        "### Step 1: Encoding Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcb68d9",
      "metadata": {
        "id": "2bcb68d9"
      },
      "outputs": [],
      "source": [
        "# TODO: Use AI to determine optimal encoding strategies\n",
        "print(\"AI-Powered Encoding Strategies:\")\n",
        "print(\"1. Intelligent encoding method selection\")\n",
        "print(\"2. Automated cardinality analysis\")\n",
        "print(\"3. Performance-based encoding optimization\")\n",
        "\n",
        "# Example: Basic encoding\n",
        "le = LabelEncoder()\n",
        "business_df_clean['license_type_encoded'] = le.fit_transform(business_df_clean['license_type'])\n",
        "\n",
        "print(\"\\nCategorical encoding applied:\")\n",
        "print(f\"License types: {business_df_clean['license_type'].unique()}\")\n",
        "print(f\"Encoded values: {business_df_clean['license_type_encoded'].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3789c13d",
      "metadata": {
        "id": "3789c13d"
      },
      "source": [
        "### Step 2: Scaling and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d8de7d",
      "metadata": {
        "id": "72d8de7d"
      },
      "outputs": [],
      "source": [
        "# TODO: Apply AI-assisted scaling and normalization\n",
        "print(\"AI-Assisted Scaling:\")\n",
        "print(\"1. Automated scaling method selection\")\n",
        "print(\"2. Intelligent outlier handling\")\n",
        "print(\"3. Performance-based scaling optimization\")\n",
        "\n",
        "# Example: Basic scaling\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = ['revenue', 'employees', 'revenue_per_employee']\n",
        "business_df_clean[numeric_cols] = scaler.fit_transform(business_df_clean[numeric_cols])\n",
        "\n",
        "print(\"\\nNumeric features scaled using StandardScaler\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29c24e2",
      "metadata": {
        "id": "f29c24e2"
      },
      "source": [
        "### Step 3: Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdc7b15b",
      "metadata": {
        "id": "bdc7b15b"
      },
      "outputs": [],
      "source": [
        "# TODO: Apply AI-assisted dimensionality reduction\n",
        "print(\"AI-Powered Dimensionality Reduction:\")\n",
        "print(\"1. Automated component selection\")\n",
        "print(\"2. Intelligent variance thresholding\")\n",
        "print(\"3. Performance-based reduction optimization\")\n",
        "\n",
        "# Example: Basic PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(business_df_clean[numeric_cols])\n",
        "\n",
        "print(f\"\\nPCA applied: {pca_features.shape}\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eaa05f3",
      "metadata": {
        "id": "5eaa05f3"
      },
      "source": [
        "## Part 6: Final Reflection and Learning Assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ff4dc64",
      "metadata": {
        "id": "3ff4dc64"
      },
      "source": [
        "### Step 1: Compare Traditional vs AI-Assisted Approaches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a70d741b",
      "metadata": {
        "id": "a70d741b"
      },
      "outputs": [],
      "source": [
        "print(\"Traditional Data Preparation:\")\n",
        "print(\"- Manual code writing\")\n",
        "print(\"- Step-by-step analysis\")\n",
        "print(\"- Custom transformations\")\n",
        "print(\"- Full control over process\")\n",
        "\n",
        "print(\"\\nAI-Assisted Data Preparation:\")\n",
        "print(\"- Automated quality assessment\")\n",
        "print(\"- Intelligent cleaning suggestions\")\n",
        "print(\"- Smart feature engineering\")\n",
        "print(\"- Faster initial insights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "941799e2",
      "metadata": {
        "id": "941799e2"
      },
      "source": [
        "### Step 2: Critical Reflection on AI-Assisted Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebef0f77",
      "metadata": {
        "id": "ebef0f77"
      },
      "outputs": [],
      "source": [
        "print(\"=== REFLECTION QUESTIONS ===\")\n",
        "print()\n",
        "print(\"1. AI TOOL EFFECTIVENESS:\")\n",
        "print(\"   - What insights did AI tools reveal that you might have missed?\")\n",
        "print(\"   - Which AI suggestions were most valuable? Which were least helpful?\")\n",
        "print(\"   - How did AI change your approach to data preparation?\")\n",
        "print()\n",
        "print(\"2. PROCESS COMPARISON:\")\n",
        "print(\"   - How did the automated approach compare to manual data preparation?\")\n",
        "print(\"   - What are the trade-offs between control and automation?\")\n",
        "print(\"   - When would you choose each approach?\")\n",
        "print()\n",
        "print(\"3. LEARNING AND SKILL DEVELOPMENT:\")\n",
        "print(\"   - What new skills did you develop using AI tools?\")\n",
        "print(\"   - How did AI help you understand data quality issues?\")\n",
        "print(\"   - What would you do differently next time?\")\n",
        "print()\n",
        "print(\"4. PRACTICAL APPLICATION:\")\n",
        "print(\"   - How would you apply these techniques to a different dataset?\")\n",
        "print(\"   - What challenges might arise in a real business context?\")\n",
        "print(\"   - How would you explain AI-assisted data prep to a colleague?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a74c5a",
      "metadata": {
        "id": "52a74c5a"
      },
      "source": [
        "### Step 3: Document Your Learning Journey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32976889",
      "metadata": {
        "id": "32976889"
      },
      "outputs": [],
      "source": [
        "print(\"=== LEARNING DOCUMENTATION ===\")\n",
        "print()\n",
        "print(\"Key Insights Gained:\")\n",
        "print(\"- [ ] Understanding of AI tool capabilities and limitations\")\n",
        "print(\"- [ ] Experience with automated data quality assessment\")\n",
        "print(\"- [ ] Practice with AI-assisted feature engineering\")\n",
        "print(\"- [ ] Critical evaluation of AI suggestions\")\n",
        "print()\n",
        "print(\"Skills Developed:\")\n",
        "print(\"- [ ] Prompting AI tools effectively for data tasks\")\n",
        "print(\"- [ ] Evaluating AI-generated suggestions critically\")\n",
        "print(\"- [ ] Balancing automation with human oversight\")\n",
        "print(\"- [ ] Documenting data preparation decisions\")\n",
        "print()\n",
        "print(\"Next Steps:\")\n",
        "print(\"- [ ] Practice with different types of datasets\")\n",
        "print(\"- [ ] Experiment with more advanced AI tools\")\n",
        "print(\"- [ ] Develop your own data preparation workflows\")\n",
        "print(\"- [ ] Share insights with peers and colleagues\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facdfda2",
      "metadata": {
        "id": "facdfda2"
      },
      "source": [
        "## Metacognitive Learning Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dc53d11",
      "metadata": {
        "id": "5dc53d11"
      },
      "source": [
        "### Reflection Questions\n",
        "- **What did you learn about your own learning process?**\n",
        "- **How would you apply this to a different domain?**\n",
        "- **What connections do you see to other concepts?**\n",
        "- **What questions do you still have?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17984af4",
      "metadata": {
        "id": "17984af4"
      },
      "source": [
        "### Transfer Applications\n",
        "- **How would this work in healthcare?**\n",
        "- **What would change if you had 10 times more data?**\n",
        "- **How would you explain this to business executives?**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72caabc7",
      "metadata": {
        "id": "72caabc7"
      },
      "source": [
        "### Expert Thinking\n",
        "- **What would an expert do differently?**\n",
        "- **What assumptions are you making?**\n",
        "- **How would you validate your approach?**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}